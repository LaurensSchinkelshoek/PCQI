{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0f20790-9890-4fa6-89f8-0c4b12f3e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import BatchNorm1d, Linear, ReLU, Sequential, MSELoss, Softmax, CrossEntropyLoss\n",
    "from torch_geometric.nn import DynamicEdgeConv, global_mean_pool\n",
    "from torch_geometric.data import Batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "57e8c003-51ad-4b60-8cec-2beddba081ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path, \"r\") as f:\n",
    "    enc_dict={-13:0,14:1,-14:2,12:3,-12:4}\n",
    "    array=f[\"y\"][7016:8032]['particle_type'].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3fe85ab6-6206-4693-a8f4-886f13ca4260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1],\n",
       "        [2],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode=OneHotEncoder()\n",
    "encode.fit(array)\n",
    "encode.transform(array).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1b9ec6a4-3c01-47c6-9497-4ba16002ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5Dataset(Dataset):\n",
    "    def __init__(self, path, features=[\"pos_x\", \"pos_y\", \"pos_z\", \"time\",\"tot\", \"dir_x\", \"dir_y\", \"dir_z\"], y_feature=\"particle_type\", particle_type=13.0, batch_size=16):\n",
    "        \"\"\" Loads the data from the hdf5 format provided by OrcaSong and converts it to data that can be used by PyTorch\n",
    "        \n",
    "        Args:\n",
    "            path (str): path to the dataset\n",
    "            features (list[str]): List of features to select from the event data and use as input features\n",
    "            y_feature  (str): Output feature to select\n",
    "            particle_type (None or float):  ID of the particle you want to classify, it will be label 0 and all else will be label 1.\n",
    "                                            Must be None when y_feature is not `particle_type`\n",
    "            batch_size (int): number of samples in mini batch\n",
    "        Examples:\n",
    "            Electron vs Background classification (default):\n",
    "            ```\n",
    "                HDF5Dataset(\"pathtodata.h5\", y_feature=\"particle_type\", particle_type=13.0)\n",
    "            ```\n",
    "            Energy regression with only xyzct:\n",
    "            ```\n",
    "                HDF5Dataset(\"pathtodata.h5\", features=[\"pos_x\", \"pos_y\", \"pos_z\", \"time\"], y_feature=\"energy\", particle_type=None)\n",
    "            ```\n",
    "\n",
    "        Lookup of table for particle_type of Leptons:\n",
    "          electron          | 11\n",
    "          electron neutrino | 12\n",
    "          muon              | 13\n",
    "          muon neutrino     | 14\n",
    "          tau               | 15\n",
    "          tau neutrino      | 16\n",
    "        Antiparticle is the same as particle but with minus sign\n",
    "        Source: https://pdg.lbl.gov/2007/reviews/montecarlorpp.pdf\n",
    "        \"\"\"\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            self.groups = list(dict(f).keys())\n",
    "            self.length = len(f[\"y\"]) // batch_size + 1\n",
    "            self._max_index = len(f[\"y\"])\n",
    "            self.encoder=OneHotEncoder(sparse=False)\n",
    "            self.encoder.fit(f[\"y\"][:2000]['particle_type'].reshape(-1,1))\n",
    "            print(\"The available y features are: \", f[\"y\"][0].dtype.names)\n",
    "        self.filename = path\n",
    "        if y_feature!=\"particle_type\":\n",
    "            assert particle_type==None, \"Selected a y_feature other than 'particle_type' and specified some value for particle_type as argument, which must be None for non particle_type output feature.\"\n",
    "        self.y_feature = y_feature\n",
    "        self.particle_type = particle_type\n",
    "        self.batch_size = batch_size\n",
    "        self._cache_x_column_names()\n",
    "        self.x_mask = self.init_x_mask(features)\n",
    "\n",
    "\n",
    "    def _cache_x_column_names(self):\n",
    "        \"\"\"Cache which columns are available in the features\n",
    "\n",
    "        Raises:\n",
    "            ValueError: It failed to read the hit_info columns\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with h5py.File(self.filename, \"r\") as f:\n",
    "                self.x_feature_dict = {\n",
    "                    f[\"x\"].attrs[f\"hit_info_{i}\"]: i for i in range(f[\"x\"].shape[-1])\n",
    "                }\n",
    "            print(\"cached the following x input features\", self.x_feature_dict)\n",
    "        except Exception:\n",
    "            raise ValueError(\"Can not read column names from dataset attributes\")\n",
    "\n",
    "    def init_x_mask(self, features):\n",
    "        \"\"\"Compute a mask that is used to select the feature columns from the data\n",
    "\n",
    "        Args:\n",
    "            features (list[str]): list of features present to load\n",
    "\n",
    "        Returns:\n",
    "            np.array: selection of column index from the features to use\n",
    "        \"\"\"\n",
    "        x_mask = [self.x_feature_dict[feat] for feat in features]\n",
    "        return np.array(x_mask)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get an sample from the h5 dataset\n",
    "        x contains: (x,y,z,ct, dir_x, dir_y, dir_z)\n",
    "        y contains a label \n",
    "\n",
    "        Args:\n",
    "            index (int): index of the batch\n",
    "\n",
    "        Returns:\n",
    "            x (torch.Tensor): Tensor with the x data (for each of the vertices)\n",
    "            y (torch.Tensor): Tensor with the y data (for the graph)\n",
    "            batch_idx (torch.Tensor): Tensor that assigns the right batch index to each x point\n",
    "        \"\"\"\n",
    "        with h5py.File(self.filename, \"r\") as f:\n",
    "            index = slice(index * self.batch_size, min(self._max_index,(index + 1) * self.batch_size))\n",
    "            \n",
    "            x = f[\"x\"][index]\n",
    "            lengths = (np.sum(x[:, :, -1:], axis=1)).astype(int)\n",
    "            batch_idx = np.hstack(\n",
    "                  [\n",
    "                      np.ones(length) * batch_idx\n",
    "                      for batch_idx, length in enumerate(lengths)\n",
    "                  ]\n",
    "              )\n",
    "            x = x[x[:, :, -1] == 1][:, self.x_mask]\n",
    "            y = self.encoder.transform(f[\"y\"][index][self.y_feature].reshape(-1,1)).argmax(1)\n",
    "            y = torch.LongTensor(y)\n",
    "            \n",
    "        return x, y, torch.LongTensor(batch_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e724e3b6-4519-4a3d-9781-3968fa0e6d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available y features are:  ('event_id', 'particle_type', 'energy', 'is_cc', 'bjorkeny', 'dir_x', 'dir_y', 'dir_z', 'time_interaction', 'run_id', 'vertex_pos_x', 'vertex_pos_y', 'vertex_pos_z', 'n_hits', 'weight_w1', 'weight_w2', 'weight_w3', 'n_gen', 'prod_identifier', 'std_dir_x', 'std_dir_y', 'std_dir_z', 'std_beta0', 'std_lik', 'std_n_hits_gandalf', 'std_pos_x', 'std_pos_y', 'std_pos_z', 'std_energy', 'std_lik_energy', 'std_length', 'group_id')\n",
      "cached the following x input features {'channel_id': 0, 'dir_x': 1, 'dir_y': 2, 'dir_z': 3, 'dom_id': 4, 'du': 5, 'floor': 6, 'group_id': 7, 'pos_x': 8, 'pos_y': 9, 'pos_z': 10, 't0': 11, 'time': 12, 'tot': 13, 'triggered': 14, 'is_valid': 15}\n"
     ]
    }
   ],
   "source": [
    "path='../project_data/small_set_1_train_0_shuffled.h5' \n",
    "train_data = HDF5Dataset(path,features=[\"pos_x\", \"pos_y\", \"pos_z\", \"time\",\"tot\", \"dir_x\", \"dir_y\", \"dir_z\"], y_feature=\"particle_type\", batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0d594c1e-2c20-4ed5-b406-711ddb218b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,i=train_data.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503deb29-a05c-4df0-ba19-5378b606bf76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "503c40fc-3988-4e46-9e8f-d14c4a063c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DECNetwork(pl.LightningModule):\n",
    "    def __init__(self, batchnorm_kwargs=None, conf=None):\n",
    "        \"\"\"Dynamic EdgeConvolution Network https://arxiv.org/abs/1801.07829 with\n",
    "           the dynamic KNN computation as presented in https://arxiv.org/abs/1902.08570 \"\"\"\n",
    "        super().__init__()\n",
    "        ## Lightning configuration\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        #self.precision = torchmetrics.Precision()\n",
    "        #self.confusionmatrix = torchmetrics.ConfusionMatrix(5)\n",
    "\n",
    "        ## Defining the Network Architecture\n",
    "        nn = Sequential(\n",
    "            Linear(2 * 8, 64),\n",
    "            BatchNorm1d(64, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "            Linear(64, 64),\n",
    "            BatchNorm1d(64, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "            Linear(64, 64),\n",
    "            BatchNorm1d(64, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "        )\n",
    "        self.edge_1 = DynamicEdgeConv(nn, aggr=\"mean\", k=32)\n",
    "        \n",
    "        nn = Sequential(\n",
    "            Linear(128, 128),\n",
    "            BatchNorm1d(128, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "            Linear(128, 128),\n",
    "            BatchNorm1d(128, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "            Linear(128, 128),\n",
    "            BatchNorm1d(128, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "        )\n",
    "        self.edge_2 = DynamicEdgeConv(nn, aggr=\"mean\", k=32)\n",
    "\n",
    "        self.shortcut_1 = Sequential(Linear(8, 64), BatchNorm1d(64), ReLU())\n",
    "        self.shortcut_2 = Sequential(Linear(64, 128), BatchNorm1d(128), ReLU())\n",
    "        self.lin_2 = Linear(128, 128)\n",
    "        self.lin_3 = Linear(128, 5)\n",
    "        self.softmax = Softmax(dim=5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, batch_idx = data.x, data.batch\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        # edgeconv layer 1\n",
    "        sc = self.shortcut_1(x)\n",
    "        x = self.edge_1(x, batch_idx)\n",
    "        x = F.relu(x + sc)\n",
    "        # edgeconv layer 2\n",
    "        sc = self.shortcut_2(x)\n",
    "        x = self.edge_2(x, batch_idx)\n",
    "        x = F.relu(x + sc)\n",
    "        x = global_mean_pool(x, batch=batch_idx)\n",
    "        # now apply\n",
    "        x = F.relu(self.lin_2(x))\n",
    "        x = self.lin_3(x)\n",
    "        return F.relu(x)\n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop. It is independent of forward\n",
    "        batch = Batch(\n",
    "            x=batch[0].squeeze(), y=batch[1].squeeze(), batch=batch[2].squeeze(),\n",
    "        )\n",
    "        out = self.forward(batch)\n",
    "        loss = F.cross_entropy(out, batch.y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log('train_acc_step', self.accuracy(F.softmax(out,dim=-1), batch.y), on_epoch=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        batch = Batch(\n",
    "            x=batch[0].squeeze(), y=batch[1].squeeze(), batch=batch[2].squeeze(),\n",
    "        )\n",
    "        y_hat = self.forward(batch)\n",
    "        loss = F.cross_entropy(y_hat, batch.y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log('valid_acc', self.accuracy(F.softmax(y_hat, dim=-1), batch.y), on_step=True, on_epoch=True)\n",
    "        #self.log('valid_matrix', self.confusionmatrix(F.softmax(y_hat), batch.y), on_epoch=True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a2071090-c754-40bc-9ff3-bc81505571ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available y features are:  ('event_id', 'particle_type', 'energy', 'is_cc', 'bjorkeny', 'dir_x', 'dir_y', 'dir_z', 'time_interaction', 'run_id', 'vertex_pos_x', 'vertex_pos_y', 'vertex_pos_z', 'n_hits', 'weight_w1', 'weight_w2', 'weight_w3', 'n_gen', 'prod_identifier', 'std_dir_x', 'std_dir_y', 'std_dir_z', 'std_beta0', 'std_lik', 'std_n_hits_gandalf', 'std_pos_x', 'std_pos_y', 'std_pos_z', 'std_energy', 'std_lik_energy', 'std_length', 'group_id')\n",
      "cached the following x input features {'channel_id': 0, 'dir_x': 1, 'dir_y': 2, 'dir_z': 3, 'dom_id': 4, 'du': 5, 'floor': 6, 'group_id': 7, 'pos_x': 8, 'pos_y': 9, 'pos_z': 10, 't0': 11, 'time': 12, 'tot': 13, 'triggered': 14, 'is_valid': 15}\n"
     ]
    }
   ],
   "source": [
    "train_data = HDF5Dataset(path,features=[\"pos_x\", \"pos_y\", \"pos_z\", \"time\",\"tot\", \"dir_x\", \"dir_y\", \"dir_z\"], y_feature=\"particle_type\", batch_size=16)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8931af3f-6a2e-45a7-ac28-e8fd1ac4ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = HDF5Dataset(\"../project_data/small_set_1_validate_0_shuffled.h5\",features=[\"pos_x\", \"pos_y\", \"pos_z\", \"time\",\"tot\", \"dir_x\", \"dir_y\", \"dir_z\"], y_feature=\"particle_type\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "197a5bd0-7a69-41f0-8e13-bd72ab9442e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-204-c769f62ef540>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-204-c769f62ef540>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    model = DECNetwork(batchnorm_kwargs={\"eps\": 1e-3, \"momentum\": 1e-1,'lr'=1e-3})\u001b[0m\n\u001b[0m                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "model = DECNetwork(batchnorm_kwargs={\"eps\": 1e-3, \"momentum\": 1e-1,'lr':1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9d5a7ece-6366-4e7c-9ee3-cb6b12d1a499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type            | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy   | Accuracy        | 0     \n",
      "1 | edge_1     | DynamicEdgeConv | 9.8 K \n",
      "2 | edge_2     | DynamicEdgeConv | 50.3 K\n",
      "3 | shortcut_1 | Sequential      | 704   \n",
      "4 | shortcut_2 | Sequential      | 8.6 K \n",
      "5 | lin_2      | Linear          | 16.5 K\n",
      "6 | lin_3      | Linear          | 645   \n",
      "7 | softmax    | Softmax         | 0     \n",
      "-----------------------------------------------\n",
      "86.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "86.5 K    Total params\n",
      "0.346     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  91%|█████████ | 25700/28179 [53:34<05:10,  8.00it/s, loss=0.918, v_num=27]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2493 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 25800/28179 [53:40<04:56,  8.01it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  92%|█████████▏| 25900/28179 [53:46<04:43,  8.03it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  92%|█████████▏| 26000/28179 [53:52<04:30,  8.04it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  93%|█████████▎| 26100/28179 [53:58<04:17,  8.06it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  93%|█████████▎| 26200/28179 [54:05<04:05,  8.07it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  93%|█████████▎| 26300/28179 [54:12<03:52,  8.09it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  94%|█████████▎| 26400/28179 [54:19<03:39,  8.10it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  94%|█████████▍| 26500/28179 [54:26<03:26,  8.11it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  94%|█████████▍| 26600/28179 [54:33<03:14,  8.13it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  95%|█████████▍| 26700/28179 [54:38<03:01,  8.15it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  95%|█████████▌| 26800/28179 [54:44<02:48,  8.16it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  95%|█████████▌| 26900/28179 [54:50<02:36,  8.17it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  96%|█████████▌| 27000/28179 [54:56<02:23,  8.19it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  96%|█████████▌| 27100/28179 [55:05<02:11,  8.20it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  97%|█████████▋| 27200/28179 [55:13<01:59,  8.21it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  97%|█████████▋| 27300/28179 [55:20<01:46,  8.22it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  97%|█████████▋| 27400/28179 [55:27<01:34,  8.24it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  98%|█████████▊| 27500/28179 [55:32<01:22,  8.25it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  98%|█████████▊| 27600/28179 [55:41<01:10,  8.26it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  98%|█████████▊| 27700/28179 [55:47<00:57,  8.27it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  99%|█████████▊| 27800/28179 [55:54<00:45,  8.29it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  99%|█████████▉| 27900/28179 [56:01<00:33,  8.30it/s, loss=0.918, v_num=27]\n",
      "Epoch 0:  99%|█████████▉| 28000/28179 [56:08<00:21,  8.31it/s, loss=0.918, v_num=27]\n",
      "Epoch 0: 100%|█████████▉| 28100/28179 [56:15<00:09,  8.32it/s, loss=0.918, v_num=27]\n",
      "Epoch 0: 100%|██████████| 28179/28179 [56:22<00:00,  8.33it/s, loss=0.814, v_num=27]\n",
      "Epoch 1:  91%|█████████ | 25700/28179 [53:32<05:09,  8.00it/s, loss=0.867, v_num=27]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2493 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 25800/28179 [53:39<04:56,  8.01it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  92%|█████████▏| 25900/28179 [53:44<04:43,  8.03it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  92%|█████████▏| 26000/28179 [53:50<04:30,  8.05it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  93%|█████████▎| 26100/28179 [53:56<04:17,  8.06it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  93%|█████████▎| 26200/28179 [54:03<04:05,  8.08it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  93%|█████████▎| 26300/28179 [54:10<03:52,  8.09it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  94%|█████████▎| 26400/28179 [54:18<03:39,  8.10it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  94%|█████████▍| 26500/28179 [54:25<03:26,  8.12it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  94%|█████████▍| 26600/28179 [54:31<03:14,  8.13it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  95%|█████████▍| 26700/28179 [54:36<03:01,  8.15it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  95%|█████████▌| 26800/28179 [54:42<02:48,  8.16it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  95%|█████████▌| 26900/28179 [54:49<02:36,  8.18it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  96%|█████████▌| 27000/28179 [54:55<02:23,  8.19it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  96%|█████████▌| 27100/28179 [55:03<02:11,  8.20it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  97%|█████████▋| 27200/28179 [55:11<01:59,  8.21it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  97%|█████████▋| 27300/28179 [55:19<01:46,  8.22it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  97%|█████████▋| 27400/28179 [55:25<01:34,  8.24it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  98%|█████████▊| 27500/28179 [55:31<01:22,  8.26it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  98%|█████████▊| 27600/28179 [55:39<01:10,  8.26it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  98%|█████████▊| 27700/28179 [55:46<00:57,  8.28it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  99%|█████████▊| 27800/28179 [55:52<00:45,  8.29it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  99%|█████████▉| 27900/28179 [55:59<00:33,  8.30it/s, loss=0.867, v_num=27]\n",
      "Epoch 1:  99%|█████████▉| 28000/28179 [56:06<00:21,  8.32it/s, loss=0.867, v_num=27]\n",
      "Epoch 1: 100%|█████████▉| 28100/28179 [56:14<00:09,  8.33it/s, loss=0.867, v_num=27]\n",
      "Epoch 1: 100%|██████████| 28179/28179 [56:20<00:00,  8.33it/s, loss=0.772, v_num=27]\n",
      "Epoch 2:  91%|█████████ | 25700/28179 [53:28<05:09,  8.01it/s, loss=0.846, v_num=27]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2493 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 25800/28179 [53:35<04:56,  8.02it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  92%|█████████▏| 25900/28179 [53:40<04:43,  8.04it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  92%|█████████▏| 26000/28179 [53:46<04:30,  8.06it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  93%|█████████▎| 26100/28179 [53:52<04:17,  8.07it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  93%|█████████▎| 26200/28179 [53:59<04:04,  8.09it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  93%|█████████▎| 26300/28179 [54:06<03:51,  8.10it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  94%|█████████▎| 26400/28179 [54:14<03:39,  8.11it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  94%|█████████▍| 26500/28179 [54:21<03:26,  8.13it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  94%|█████████▍| 26600/28179 [54:27<03:13,  8.14it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  95%|█████████▍| 26700/28179 [54:32<03:01,  8.16it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  95%|█████████▌| 26800/28179 [54:38<02:48,  8.17it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  95%|█████████▌| 26900/28179 [54:45<02:36,  8.19it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  96%|█████████▌| 27000/28179 [54:51<02:23,  8.20it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  96%|█████████▌| 27100/28179 [55:00<02:11,  8.21it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  97%|█████████▋| 27200/28179 [55:08<01:59,  8.22it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  97%|█████████▋| 27300/28179 [55:15<01:46,  8.23it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  97%|█████████▋| 27400/28179 [55:21<01:34,  8.25it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  98%|█████████▊| 27500/28179 [55:27<01:22,  8.26it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  98%|█████████▊| 27600/28179 [55:35<01:09,  8.27it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  98%|█████████▊| 27700/28179 [55:42<00:57,  8.29it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  99%|█████████▊| 27800/28179 [55:49<00:45,  8.30it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  99%|█████████▉| 27900/28179 [55:56<00:33,  8.31it/s, loss=0.846, v_num=27]\n",
      "Epoch 2:  99%|█████████▉| 28000/28179 [56:03<00:21,  8.32it/s, loss=0.846, v_num=27]\n",
      "Epoch 2: 100%|█████████▉| 28100/28179 [56:10<00:09,  8.34it/s, loss=0.846, v_num=27]\n",
      "Epoch 2: 100%|██████████| 28179/28179 [56:17<00:00,  8.34it/s, loss=0.756, v_num=27]\n",
      "Epoch 3:  91%|█████████ | 25700/28179 [53:30<05:09,  8.01it/s, loss=0.833, v_num=27]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2493 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 25800/28179 [53:36<04:56,  8.02it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  92%|█████████▏| 25900/28179 [53:42<04:43,  8.04it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  92%|█████████▏| 26000/28179 [53:48<04:30,  8.05it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  93%|█████████▎| 26100/28179 [53:54<04:17,  8.07it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  93%|█████████▎| 26200/28179 [54:01<04:04,  8.08it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  93%|█████████▎| 26300/28179 [54:08<03:52,  8.10it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  94%|█████████▎| 26400/28179 [54:15<03:39,  8.11it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  94%|█████████▍| 26500/28179 [54:22<03:26,  8.12it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  94%|█████████▍| 26600/28179 [54:29<03:14,  8.14it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  95%|█████████▍| 26700/28179 [54:34<03:01,  8.15it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  95%|█████████▌| 26800/28179 [54:40<02:48,  8.17it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  95%|█████████▌| 26900/28179 [54:46<02:36,  8.18it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  96%|█████████▌| 27000/28179 [54:52<02:23,  8.20it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  96%|█████████▌| 27100/28179 [55:01<02:11,  8.21it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  97%|█████████▋| 27200/28179 [55:09<01:59,  8.22it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  97%|█████████▋| 27300/28179 [55:17<01:46,  8.23it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  97%|█████████▋| 27400/28179 [55:23<01:34,  8.24it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  98%|█████████▊| 27500/28179 [55:29<01:22,  8.26it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  98%|█████████▊| 27600/28179 [55:37<01:10,  8.27it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  98%|█████████▊| 27700/28179 [55:44<00:57,  8.28it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  99%|█████████▊| 27800/28179 [55:50<00:45,  8.30it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  99%|█████████▉| 27900/28179 [55:57<00:33,  8.31it/s, loss=0.833, v_num=27]\n",
      "Epoch 3:  99%|█████████▉| 28000/28179 [56:04<00:21,  8.32it/s, loss=0.833, v_num=27]\n",
      "Epoch 3: 100%|█████████▉| 28100/28179 [56:12<00:09,  8.33it/s, loss=0.833, v_num=27]\n",
      "Epoch 3: 100%|██████████| 28179/28179 [56:18<00:00,  8.34it/s, loss=0.748, v_num=27]\n",
      "Epoch 4:  91%|█████████ | 25700/28179 [53:30<05:09,  8.01it/s, loss=0.823, v_num=27]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2493 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 25800/28179 [53:37<04:56,  8.02it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  92%|█████████▏| 25900/28179 [53:42<04:43,  8.04it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  92%|█████████▏| 26000/28179 [53:48<04:30,  8.05it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  93%|█████████▎| 26100/28179 [53:54<04:17,  8.07it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  93%|█████████▎| 26200/28179 [54:01<04:04,  8.08it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  93%|█████████▎| 26300/28179 [54:08<03:52,  8.10it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  94%|█████████▎| 26400/28179 [54:16<03:39,  8.11it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  94%|█████████▍| 26500/28179 [54:23<03:26,  8.12it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  94%|█████████▍| 26600/28179 [54:29<03:14,  8.14it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  95%|█████████▍| 26700/28179 [54:34<03:01,  8.15it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  95%|█████████▌| 26800/28179 [54:40<02:48,  8.17it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  95%|█████████▌| 26900/28179 [54:47<02:36,  8.18it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  96%|█████████▌| 27000/28179 [54:53<02:23,  8.20it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  96%|█████████▌| 27100/28179 [55:02<02:11,  8.21it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  97%|█████████▋| 27200/28179 [55:10<01:59,  8.22it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  97%|█████████▋| 27300/28179 [55:17<01:46,  8.23it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  97%|█████████▋| 27400/28179 [55:23<01:34,  8.24it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  98%|█████████▊| 27500/28179 [55:29<01:22,  8.26it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  98%|█████████▊| 27600/28179 [55:37<01:10,  8.27it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  98%|█████████▊| 27700/28179 [55:44<00:57,  8.28it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  99%|█████████▊| 27800/28179 [55:51<00:45,  8.30it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  99%|█████████▉| 27900/28179 [55:58<00:33,  8.31it/s, loss=0.823, v_num=27]\n",
      "Epoch 4:  99%|█████████▉| 28000/28179 [56:05<00:21,  8.32it/s, loss=0.823, v_num=27]\n",
      "Epoch 4: 100%|█████████▉| 28100/28179 [56:12<00:09,  8.33it/s, loss=0.823, v_num=27]\n",
      "Epoch 4: 100%|██████████| 28179/28179 [56:19<00:00,  8.34it/s, loss=0.738, v_num=27]\n",
      "Epoch 5:  91%|█████████ | 25700/28179 [53:30<05:09,  8.00it/s, loss=0.815, v_num=27]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/2493 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 25800/28179 [53:37<04:56,  8.02it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  92%|█████████▏| 25900/28179 [53:43<04:43,  8.04it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  92%|█████████▏| 26000/28179 [53:49<04:30,  8.05it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  93%|█████████▎| 26100/28179 [53:55<04:17,  8.07it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  93%|█████████▎| 26200/28179 [54:02<04:04,  8.08it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  93%|█████████▎| 26300/28179 [54:09<03:52,  8.09it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  94%|█████████▎| 26400/28179 [54:16<03:39,  8.11it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  94%|█████████▍| 26500/28179 [54:23<03:26,  8.12it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  94%|█████████▍| 26600/28179 [54:30<03:14,  8.13it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  95%|█████████▍| 26700/28179 [54:35<03:01,  8.15it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  95%|█████████▌| 26800/28179 [54:41<02:48,  8.17it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  95%|█████████▌| 26900/28179 [54:47<02:36,  8.18it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  96%|█████████▌| 27000/28179 [54:53<02:23,  8.20it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  96%|█████████▌| 27100/28179 [55:02<02:11,  8.21it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  97%|█████████▋| 27200/28179 [55:10<01:59,  8.22it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  97%|█████████▋| 27300/28179 [55:18<01:46,  8.23it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  97%|█████████▋| 27400/28179 [55:24<01:34,  8.24it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  98%|█████████▊| 27500/28179 [55:30<01:22,  8.26it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  98%|█████████▊| 27600/28179 [55:38<01:10,  8.27it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  98%|█████████▊| 27700/28179 [55:45<00:57,  8.28it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  99%|█████████▊| 27800/28179 [55:51<00:45,  8.29it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  99%|█████████▉| 27900/28179 [55:58<00:33,  8.31it/s, loss=0.815, v_num=27]\n",
      "Epoch 5:  99%|█████████▉| 28000/28179 [56:05<00:21,  8.32it/s, loss=0.815, v_num=27]\n",
      "Epoch 5: 100%|█████████▉| 28100/28179 [56:13<00:09,  8.33it/s, loss=0.815, v_num=27]\n",
      "Epoch 5: 100%|██████████| 28179/28179 [56:19<00:00,  8.34it/s, loss=0.734, v_num=27]\n",
      "Epoch 5: 100%|██████████| 28179/28179 [56:19<00:00,  8.34it/s, loss=0.734, v_num=27]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    gpus=1,\n",
    "    precision=32,\n",
    "    log_every_n_steps=10,\n",
    "    progress_bar_refresh_rate=100,\n",
    "    fast_dev_run=False,\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9445393e-9e60-45c2-805e-178f1e995439",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(trainer.log_dir+\"/trained_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6ece25f7-fdda-4802-a79f-4b31e71a541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2e7bcd0b-afa0-4ae6-ab83-415fcdfb20ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x7fefc0651d00>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6242afa-6f1e-425b-97d9-5e9c2a9875b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b651e0-bdc4-40c3-bb54-ec0d67b0bd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
