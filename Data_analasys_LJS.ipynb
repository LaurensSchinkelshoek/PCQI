{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7620377-67b0-4e66-92c6-c02a3dfe3a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.7.0+cu101 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (1.7.0+cu101)\n",
      "Requirement already satisfied: numpy in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch==1.7.0+cu101) (1.20.2)\n",
      "Requirement already satisfied: dataclasses in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch==1.7.0+cu101) (0.6)\n",
      "Requirement already satisfied: typing-extensions in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch==1.7.0+cu101) (3.7.4.3)\n",
      "Requirement already satisfied: future in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch==1.7.0+cu101) (0.18.2)\n",
      "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
      "Requirement already satisfied: torch-scatter in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (2.0.6)\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
      "Requirement already satisfied: torch-sparse in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (0.6.9)\n",
      "Requirement already satisfied: scipy in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-sparse) (1.6.2)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from scipy->torch-sparse) (1.20.2)\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
      "Requirement already satisfied: torch-cluster in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (1.5.9)\n",
      "Requirement already satisfied: torch-geometric==1.6.3 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (1.6.3)\n",
      "Requirement already satisfied: ase in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (3.21.1)\n",
      "Requirement already satisfied: googledrivedownloader in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (0.4)\n",
      "Requirement already satisfied: h5py in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (2.11.3)\n",
      "Requirement already satisfied: networkx in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (2.5.1)\n",
      "Requirement already satisfied: numba in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (0.53.1)\n",
      "Requirement already satisfied: numpy in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (1.20.2)\n",
      "Requirement already satisfied: pandas in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (1.2.4)\n",
      "Requirement already satisfied: python-louvain in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (0.15)\n",
      "Requirement already satisfied: rdflib in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (5.0.0)\n",
      "Requirement already satisfied: requests in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (2.25.1)\n",
      "Requirement already satisfied: scikit-learn in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (0.24.1)\n",
      "Requirement already satisfied: scipy in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (1.6.2)\n",
      "Requirement already satisfied: torch in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (1.7.0+cu101)\n",
      "Requirement already satisfied: tqdm in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch-geometric==1.6.3) (4.60.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from ase->torch-geometric==1.6.3) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from jinja2->torch-geometric==1.6.3) (1.1.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from networkx->torch-geometric==1.6.3) (4.4.2)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from numba->torch-geometric==1.6.3) (0.36.0)\n",
      "Requirement already satisfied: setuptools in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from numba->torch-geometric==1.6.3) (44.0.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from pandas->torch-geometric==1.6.3) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from pandas->torch-geometric==1.6.3) (2.8.1)\n",
      "Requirement already satisfied: pyparsing in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from rdflib->torch-geometric==1.6.3) (2.4.7)\n",
      "Requirement already satisfied: six in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from rdflib->torch-geometric==1.6.3) (1.15.0)\n",
      "Requirement already satisfied: isodate in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from rdflib->torch-geometric==1.6.3) (0.6.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from requests->torch-geometric==1.6.3) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from requests->torch-geometric==1.6.3) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from requests->torch-geometric==1.6.3) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from requests->torch-geometric==1.6.3) (2.10)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from scikit-learn->torch-geometric==1.6.3) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from scikit-learn->torch-geometric==1.6.3) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch->torch-geometric==1.6.3) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch->torch-geometric==1.6.3) (0.6)\n",
      "Requirement already satisfied: future in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch->torch-geometric==1.6.3) (0.18.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from matplotlib>=2.0.0->ase->torch-geometric==1.6.3) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from matplotlib>=2.0.0->ase->torch-geometric==1.6.3) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from matplotlib>=2.0.0->ase->torch-geometric==1.6.3) (8.2.0)\n",
      "Requirement already satisfied: pytorch-lightning==1.1.8 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (1.1.8)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from pytorch-lightning==1.1.8) (1.20.2)\n",
      "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from pytorch-lightning==1.1.8) (5.3.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from pytorch-lightning==1.1.8) (0.18.2)\n",
      "Requirement already satisfied: torch>=1.3 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from pytorch-lightning==1.1.8) (1.7.0+cu101)\n",
      "Requirement already satisfied: fsspec[http]>=0.8.1 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from pytorch-lightning==1.1.8) (2021.4.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from pytorch-lightning==1.1.8) (2.4.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from pytorch-lightning==1.1.8) (4.60.0)\n",
      "Requirement already satisfied: dataclasses in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch>=1.3->pytorch-lightning==1.1.8) (0.6)\n",
      "Requirement already satisfied: typing-extensions in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from torch>=1.3->pytorch-lightning==1.1.8) (3.7.4.3)\n",
      "Requirement already satisfied: requests; extra == \"http\" in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.1.8) (2.25.1)\n",
      "Requirement already satisfied: aiohttp; extra == \"http\" in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.1.8) (3.7.4.post0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.8) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.8) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.8) (0.4.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.8) (1.37.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.8) (3.15.8)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.8) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.8) (1.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.8) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.8) (44.0.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.8) (0.36.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.8) (1.29.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.1.8) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.1.8) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.1.8) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.1.8) (2020.12.5)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.1.8) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.1.8) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.1.8) (1.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.1.8) (20.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1.8) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.8) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.8) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.8) (4.2.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1.8) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/laurens/PCQI/pcqi_env/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.8) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip uninstall -y torchtext\n",
    "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "!pip install torch-geometric==1.6.3\n",
    "!pip install pytorch-lightning==1.1.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09fda264-dabf-4674-86e4-ec697144fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import BatchNorm1d, Linear, ReLU, Sequential\n",
    "from torch_geometric.nn import DynamicEdgeConv, global_mean_pool\n",
    "from torch_geometric.data import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bc8d2d-443d-471a-9429-d4d36885ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5Dataset(Dataset):\n",
    "    def __init__(self, path, features=[\"pos_x\", \"pos_y\", \"pos_z\", \"time\", \"dir_x\", \"dir_y\", \"dir_z\"], y_feature=\"particle_type\", particle_type=13.0, batch_size=64):\n",
    "        \"\"\" Loads the data from the hdf5 format provided by OrcaSong and converts it to data that can be used by PyTorch\n",
    "        \n",
    "        Args:\n",
    "            path (str): path to the dataset\n",
    "            features (list[str]): List of features to select from the event data and use as input features\n",
    "            y_feature  (str): Output feature to select\n",
    "            particle_type (None or float):  ID of the particle you want to classify, it will be label 0 and all else will be label 1.\n",
    "                                            Must be None when y_feature is not `particle_type`\n",
    "            batch_size (int): number of samples in mini batch\n",
    "        Examples:\n",
    "            Electron vs Background classification (default):\n",
    "            ```\n",
    "                HDF5Dataset(\"pathtodata.h5\", y_feature=\"particle_type\", particle_type=13.0)\n",
    "            ```\n",
    "            Energy regression with only xyzct:\n",
    "            ```\n",
    "                HDF5Dataset(\"pathtodata.h5\", features=[\"pos_x\", \"pos_y\", \"pos_z\", \"time\"], y_feature=\"energy\", particle_type=None)\n",
    "            ```\n",
    "\n",
    "        Lookup of table for particle_type of Leptons:\n",
    "          electron          | 11\n",
    "          electron neutrino | 12\n",
    "          muon              | 13\n",
    "          muon neutrino     | 14\n",
    "          tau               | 15\n",
    "          tau neutrino      | 16\n",
    "        Antiparticle is the same as particle but with minus sign\n",
    "        Source: https://pdg.lbl.gov/2007/reviews/montecarlorpp.pdf\n",
    "        \"\"\"\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            self.groups = list(dict(f).keys())\n",
    "            self.length = len(f[\"y\"]) // batch_size + 1\n",
    "            self._max_index = len(f[\"y\"])\n",
    "            print(\"The available y features are: \", f[\"y\"][0].dtype.names)\n",
    "        self.filename = path\n",
    "        if y_feature!=\"particle_type\":\n",
    "            assert particle_type==None, \"Selected a y_feature other than 'particle_type' and specified some value for particle_type as argument, which must be None for non particle_type output feature.\"\n",
    "        self.y_feature = y_feature\n",
    "        self.particle_type = particle_type\n",
    "        self.batch_size = batch_size\n",
    "        self._cache_x_column_names()\n",
    "        self.x_mask = self.init_x_mask(features)\n",
    "\n",
    "\n",
    "    def _cache_x_column_names(self):\n",
    "        \"\"\"Cache which columns are available in the features\n",
    "\n",
    "        Raises:\n",
    "            ValueError: It failed to read the hit_info columns\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with h5py.File(self.filename, \"r\") as f:\n",
    "                self.x_feature_dict = {\n",
    "                    f[\"x\"].attrs[f\"hit_info_{i}\"]: i for i in range(f[\"x\"].shape[-1])\n",
    "                }\n",
    "            print(\"cached the following x input features\", self.x_feature_dict)\n",
    "        except Exception:\n",
    "            raise ValueError(\"Can not read column names from dataset attributes\")\n",
    "\n",
    "    def init_x_mask(self, features):\n",
    "        \"\"\"Compute a mask that is used to select the feature columns from the data\n",
    "\n",
    "        Args:\n",
    "            features (list[str]): list of features present to load\n",
    "\n",
    "        Returns:\n",
    "            np.array: selection of column index from the features to use\n",
    "        \"\"\"\n",
    "        x_mask = [self.x_feature_dict[feat] for feat in features]\n",
    "        return np.array(x_mask)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get an sample from the h5 dataset\n",
    "        x contains: (x,y,z,ct, dir_x, dir_y, dir_z)\n",
    "        y contains a label neutrino (1) or muon (0)\n",
    "\n",
    "        Args:\n",
    "            index (int): index of the batch\n",
    "\n",
    "        Returns:\n",
    "            x (torch.Tensor): Tensor with the x data (for each of the vertices)\n",
    "            y (torch.Tensor): Tensor with the y data (for the graph)\n",
    "            batch_idx (torch.Tensor): Tensor that assigns the right batch index to each x point\n",
    "        \"\"\"\n",
    "        with h5py.File(self.filename, \"r\") as f:\n",
    "            if (index + 1) * self.batch_size >= self._max_index:\n",
    "                  index = slice(index * self.batch_size, self._max_index)\n",
    "            else:\n",
    "                  index = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
    "            x = f[\"x\"][index][:]\n",
    "            lengths = (np.sum(x[:, :, -1:], axis=1)).astype(int)\n",
    "            batch_idx = np.hstack(\n",
    "                  [\n",
    "                      np.ones(length) * batch_idx\n",
    "                      for batch_idx, length in enumerate(lengths)\n",
    "                  ]\n",
    "              )\n",
    "            x = x[x[:, :, -1] == 1][:, self.x_mask]\n",
    "            y = f[\"y\"][index][:][self.y_feature]\n",
    "            if self.y_feature==\"particle_type\" and self.particle_type:\n",
    "                y = torch.LongTensor(~(abs(y) == self.particle_type))\n",
    "            else:\n",
    "                y = torch.Tensor(y)\n",
    "        return x, y, torch.LongTensor(batch_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bfb6305-2d90-4ab3-837e-f4d0e0446e6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-db23d4716a2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDECNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchnorm_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \"\"\"Dynamic EdgeConvolution Network https://arxiv.org/abs/1801.07829 with\n\u001b[1;32m      4\u001b[0m            the dynamic KNN computation as presented in https://arxiv.org/abs/1902.08570 \"\"\"\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "class DECNetwork(pl.LightningModule):\n",
    "    def __init__(self, batchnorm_kwargs=None, conf=None):\n",
    "        \"\"\"Dynamic EdgeConvolution Network https://arxiv.org/abs/1801.07829 with\n",
    "           the dynamic KNN computation as presented in https://arxiv.org/abs/1902.08570 \"\"\"\n",
    "        super().__init__()\n",
    "        ## Lightning configuration\n",
    "        self.accuracy = pl.metrics.Accuracy()\n",
    "        ## Defining the Network Architecture\n",
    "        nn = Sequential(\n",
    "            Linear(2 * 7, 64),\n",
    "            BatchNorm1d(64, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "            Linear(64, 64),\n",
    "            BatchNorm1d(64, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "            Linear(64, 64),\n",
    "            BatchNorm1d(64, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "        )\n",
    "        self.edge_1 = DynamicEdgeConv(nn, aggr=\"mean\", k=32)\n",
    "        nn = Sequential(\n",
    "            Linear(128, 128),\n",
    "            BatchNorm1d(128, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "            Linear(128, 128),\n",
    "            BatchNorm1d(128, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "            Linear(128, 128),\n",
    "            BatchNorm1d(128, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "        )\n",
    "        self.edge_2 = DynamicEdgeConv(nn, aggr=\"mean\", k=32)\n",
    "        nn = Sequential(\n",
    "            Linear(256, 256),\n",
    "            BatchNorm1d(256, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "            Linear(256, 256),\n",
    "            BatchNorm1d(256, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "            Linear(256, 256),\n",
    "            BatchNorm1d(256, **batchnorm_kwargs),\n",
    "            ReLU(),\n",
    "        )\n",
    "        self.edge_3 = DynamicEdgeConv(nn, aggr=\"mean\", k=32)\n",
    "        self.shortcut_1 = Sequential(Linear(7, 64), BatchNorm1d(64), ReLU())\n",
    "        self.shortcut_2 = Sequential(Linear(64, 128), BatchNorm1d(128), ReLU())\n",
    "        self.shortcut_3 = Sequential(Linear(128, 256), BatchNorm1d(256), ReLU())\n",
    "        self.lin_1 = Linear(256, 256)\n",
    "        self.lin_2 = Linear(256, 128)\n",
    "        self.lin_3 = Linear(128, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, batch_idx = data.x, data.batch\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        # edgeconv layer 1\n",
    "        sc = self.shortcut_1(x)\n",
    "        x = self.edge_1(x, batch_idx)\n",
    "        x = F.relu(x + sc)\n",
    "        # edgeconv layer 2\n",
    "        sc = self.shortcut_2(x)\n",
    "        x = self.edge_2(x, batch_idx)\n",
    "        x = F.relu(x + sc)\n",
    "        # edgeconv layer 3\n",
    "        sc = self.shortcut_3(x)\n",
    "        x = self.edge_3(x, batch_idx)\n",
    "        x = F.relu(x + sc)\n",
    "        x = global_mean_pool(x, batch=batch_idx)\n",
    "        # now apply\n",
    "        x = F.relu(self.lin_1(x))\n",
    "        x = F.relu(self.lin_2(x))\n",
    "        x = self.lin_3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop. It is independent of forward\n",
    "        batch = Batch(\n",
    "            x=batch[0].squeeze(), y=batch[1].squeeze(), batch=batch[2].squeeze(),\n",
    "        )\n",
    "        out = self.forward(batch)\n",
    "        loss = F.nll_loss(out, batch.y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log('train_acc_step', self.accuracy(out, batch.y), on_epoch=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        batch = Batch(\n",
    "            x=batch[0].squeeze(), y=batch[1].squeeze(), batch=batch[2].squeeze(),\n",
    "        )\n",
    "        y_hat = self.forward(batch)\n",
    "        loss = F.nll_loss(y_hat, batch.y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log('valid_acc', self.accuracy(y_hat, batch.y), on_step=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7963d2-c30a-40e2-94bf-2e6fa1dde67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73c12ac-7e81-49ca-b731-99779a4cb04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available y features are:  ('event_id', 'particle_type', 'energy', 'is_cc', 'bjorkeny', 'dir_x', 'dir_y', 'dir_z', 'time_interaction', 'run_id', 'vertex_pos_x', 'vertex_pos_y', 'vertex_pos_z', 'n_hits', 'weight_w1', 'weight_w2', 'weight_w3', 'n_gen', 'prod_identifier', 'std_dir_x', 'std_dir_y', 'std_dir_z', 'std_beta0', 'std_lik', 'std_n_hits_gandalf', 'std_pos_x', 'std_pos_y', 'std_pos_z', 'std_energy', 'std_lik_energy', 'std_length', 'group_id')\n",
      "cached the following x input features {'channel_id': 0, 'dir_x': 1, 'dir_y': 2, 'dir_z': 3, 'dom_id': 4, 'du': 5, 'floor': 6, 'group_id': 7, 'pos_x': 8, 'pos_y': 9, 'pos_z': 10, 't0': 11, 'time': 12, 'tot': 13, 'triggered': 14, 'is_valid': 15}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'n_hits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b3df555a2629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDF5Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"small_set_1_train_0_shuffled.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pos_x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pos_y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pos_z\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dir_x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dir_y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dir_z\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"n_hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"energy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticle_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-6cbf4990e8b9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, features, y_feature, particle_type, batch_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_x_column_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_x_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6cbf4990e8b9>\u001b[0m in \u001b[0;36minit_x_mask\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mselection\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mx_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_feature_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6cbf4990e8b9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mselection\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mx_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_feature_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n_hits'"
     ]
    }
   ],
   "source": [
    "train_data = HDF5Dataset(\"small_set_1_train_0_shuffled.h5\",features=[\"pos_x\", \"pos_y\", \"pos_z\", \"time\", \"dir_x\", \"dir_y\", \"dir_z\",\"n_hits\"], y_feature=[\"energy\"], particle_type=None, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a3caee-8ea2-400d-92f4-321362236c33",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HDF5Dataset' object has no attribute 'dataloader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-894c1f5ce9f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HDF5Dataset' object has no attribute 'dataloader'"
     ]
    }
   ],
   "source": [
    "for a in train_data.dataloader:\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e6e86-a442-46b8-959e-6e86fd650484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
